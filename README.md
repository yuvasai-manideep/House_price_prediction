# House_price_prediction
Prediction of House_price by using python models. 

The aim of the project is to predict house price for the given Dataset. The Data id divided into Train, Test datasets and the price of the test data is to be estimated. Here I have used Linear Regression, random forest method and Decision tree algorithm for prediction. 
## Required Libraries:
    Pandas
    NumPy
    Matplotlib
    Sklearn
## Steps in House price prediction:
     1.	Loading data
     2.	Data Exploration
     3.	Model building
     4.	Visualization
## Problem Statement
     The goal is to understand the relationship between house features and how these variables affect the house price.
 Dataset contains 9 columns and 415 rows with CSV extension. The data contains the following columns:
•	Transaction date
•	House Age
•	Distance from nearest Metro station (km)
•	Number of convenience stores
•	Latitude
•	Longitude
•	Number of bedrooms
•	House size (sqft)
•	House price of unit area

In this House price prediction, I used 4 prediction model i.e., Linear Regression, Random Forest model, Decision tree algorithm, XG Boost.
    
Linear regression analysis is used to predict the value of a variable based on the value of another variable. The variable you want to predict is called the dependent variable. The variable you are using to predict the other variable's value is called the independent variable.

Random forest is a Supervised Machine Learning Algorithm that is used widely in Classification and Regression problems. It builds decision trees on different samples and takes their majority vote for classification and average in case of regression. One of the most important features of the Random Forest Algorithm is that it can handle the data set containing continuous variables as in the case of regression and categorical variables as in the case of classification. It performs better results for classification problems.

Decision Trees are a type of Supervised Machine Learning where the data is continuously split according to a certain parameter. The tree can be explained by two entities, namely decision nodes and leaves.

XG Boost stands for Extreme Gradient Boosting. XGBoost is an implementation of Gradient Boosted decision trees. In this algorithm, decision trees are created in sequential form. Weights play an important role in XG Boost. 
